{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rr_8_8\n",
      "Tensor(\"Relu_64:0\", shape=(10, 20, 20, 32), dtype=float32)\n",
      "rout_1_1\n",
      "Tensor(\"Add:0\", shape=(10, 20, 20, 32), dtype=float32)\n",
      "r1\n",
      "Tensor(\"concat:0\", shape=(10, 20, 160, 32), dtype=float32)\n",
      "rtotal\n",
      "Tensor(\"concat_8:0\", shape=(10, 160, 160, 32), dtype=float32)\n",
      "mpool\n",
      "Tensor(\"MaxPool:0\", shape=(10, 80, 80, 32), dtype=float32)\n",
      "Tensor(\"Relu_71:0\", shape=(10, 27, 27, 16), dtype=float32)\n",
      "Tensor(\"dropout/mul_1:0\", shape=(10, 4096), dtype=float32)\n",
      "Tensor(\"dropout_1/mul_1:0\", shape=(10, 2048), dtype=float32)\n",
      "Tensor(\"Add_66:0\", shape=(10, 2), dtype=float32)\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "Iter 50, Minibatch Loss= 3751147995136.000000, Training Accuracy= 0.50000\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "# from PIL import Image, ImageFile\n",
    "import matplotlib.image as mpimg\n",
    "from numpy import genfromtxt\n",
    "from numpy.random import permutation\n",
    "\n",
    "#read data into memory\n",
    "my_data   = genfromtxt('/root/mydataset_higher_5_6', delimiter=',', dtype=None)\n",
    "batch_y_t = np.zeros([len(my_data), 2])\n",
    "batch_x_t = []\n",
    "index     = 0\n",
    "\n",
    "for a in my_data:\n",
    "    if a[0] == 5:\n",
    "        batch_y_t[index][0] = 1\n",
    "    else:\n",
    "        batch_y_t[index][1] = 1\n",
    "    batch_x_t.append(a[1])\n",
    "    index = index+1\n",
    "    \n",
    "batch_x_t = np.asarray(batch_x_t)\n",
    "\n",
    "def get_next_batch(start_i, end_i):\n",
    "    btc = []\n",
    "    for i in range(start_i, end_i+1):\n",
    "        global batch_x_t\n",
    "        global batch_y_t\n",
    "        img = mpimg.imread('/root/dataset_png/'+batch_x_t[i])\n",
    "#         print(img.shape)\n",
    "        greyscale_map = img.flatten()\n",
    "        greyscale_map = np.array(greyscale_map)\n",
    "        btc.append(greyscale_map.ravel())\n",
    "    return np.asarray(btc).astype('float32'), batch_y_t[start_i:end_i+1]\n",
    "\n",
    "\n",
    "\n",
    "#Permute data\n",
    "p = permutation(len(batch_y_t))\n",
    "batch_x_t = batch_x_t[p]\n",
    "batch_y_t = batch_y_t[p]\n",
    "\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "n_input       = 65*65*65\n",
    "n_classes     = 5     # total classes currently we will only take 2\n",
    "dropout       = 0.5   # Dropout, probability to keep units\n",
    "learning_rate = 0.001\n",
    "batch_size    = 10\n",
    "display_step  = 5\n",
    "\n",
    "\n",
    "training_iters  = 1200\n",
    "\n",
    "\n",
    "# tf Graph input\n",
    "x         = tf.placeholder(tf.float32, [None, 65 * 65 * 65])\n",
    "y         = tf.placeholder(tf.float32, [None, 5])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "def conv3d(x, W, b):\n",
    "    x  = tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='VALID')\n",
    "    x  = tf.nn.bias_add(x, b)\n",
    "    pp = tf.nn.relu(x)\n",
    "    return pp\n",
    "\n",
    "\n",
    "def maxpool3d(x):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='VALID')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    \n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 65, 65, 65])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv3d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool3d(conv1)\n",
    "    \n",
    "    conv2 = conv3d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool3d(conv2)\n",
    "    \n",
    "    conv3 = conv3d(conv2, weights['wc3'], biases['bc3'])\n",
    "    \n",
    "    conv4 = conv3d(conv3, weights['wc4'], biases['bc4'])\n",
    "    \n",
    "    conv5 = conv3d(conv4, weights['wc5'], biases['bc5'])\n",
    "    \n",
    "    \n",
    "    #Fully connected layer fc1\n",
    "    fc1 = tf.reshape(conv5, [-1, weights['w_fc1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['w_fc1']), biases['b_fc1'])\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    print(fc1)\n",
    "    #Fully connected layer fc2\n",
    "    fc2 = tf.reshape(fc1, [-1, weights['w_fc2'].get_shape().as_list()[0]])\n",
    "    fc2 = tf.add(tf.matmul(fc2, weights['w_fc2']), biases['b_fc2'])\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "    \n",
    "    \n",
    "    print(fc2)\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc2, weights['w_out']), biases['b_out'])\n",
    "    print(out)\n",
    "    return out\n",
    "    \n",
    "    \n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    \n",
    "    #6x6x6 conv, 65x65x65 1 input,  32 outputs, conv1 layer\n",
    "    'wc1': tf.Variable(tf.random_normal([6, 6, 6, 1, 32])),\n",
    "    #5x5x5 conv, 30x30x30 32 input, 16 outputs, conv2 layer\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 5, 32, 16])),\n",
    "    #5x5x5 conv, 26x26x26 16 input, 16 outputs, conv3 layer\n",
    "    'wc3': tf.Variable(tf.random_normal([5, 5, 5, 16, 16])),\n",
    "    #4x4x4 conv, 22x22x22 16 input, 16 outputs, conv4 layer\n",
    "    'wc4': tf.Variable(tf.random_normal([4, 4, 4, 16, 16])),\n",
    "    #3x3x3 conv, 19x19x19 16 input, 16 outputs, conv5 layer\n",
    "    'wc5': tf.Variable(tf.random_normal([3, 3, 3, 16, 16])),\n",
    "    \n",
    "    # fully connected, 17*17*17*16 inputs, 4096 outputs\n",
    "    'w_fc1': tf.Variable(tf.random_normal([17*17*17*16, 4096])),\n",
    "    # fully connected, 4096 inputs, 2048 outputs\n",
    "    'w_fc2': tf.Variable(tf.random_normal([4096, 2048])),\n",
    "    # fully connected, 2048 inputs, 2 outputs\n",
    "    'w_out': tf.Variable(tf.random_normal([2048, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    #convolution layer biases\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([16])),\n",
    "    'bc3': tf.Variable(tf.random_normal([16])),\n",
    "    'bc4': tf.Variable(tf.random_normal([16])),\n",
    "    'bc5': tf.Variable(tf.random_normal([16])),\n",
    "    \n",
    "    \n",
    "    #fully connected layers biases\n",
    "    'b_fc1': tf.Variable(tf.random_normal([4096])),\n",
    "    'b_fc2': tf.Variable(tf.random_normal([2048])),\n",
    "    'b_out': tf.Variable(tf.random_normal([5]))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "# sigmoid_cross_entropy_with_logits\n",
    "cost      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy     = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "#flag for training or testing\n",
    "training = True\n",
    "\n",
    "\n",
    "sess  = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if training:\n",
    "    # Launch the graph\n",
    "    # with tf.Session() as sess:\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    itera = 0\n",
    "    while itera < 3:\n",
    "        step = 1\n",
    "        # Keep training until reach max iterations\n",
    "        while step * batch_size < training_iters:\n",
    "            batch_x, batch_y  = get_next_batch((step-1)*batch_size, step*batch_size-1)\n",
    "\n",
    "            print(len(batch_x))\n",
    "            print(len(batch_y))\n",
    "            # logits and labels must be same size\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                           keep_prob: dropout})\n",
    "            if step % display_step == 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                                  y: batch_y,\n",
    "                                                                  keep_prob: 1.})\n",
    "                print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "            step += 1\n",
    "        \n",
    "        #if(itera == 2):\n",
    "        saver.save(sess, \"model_5_6_a.ckpt\", itera)\n",
    "        print(\"Optimization Finished!\")\n",
    "        itera = itera+1\n",
    "else:\n",
    "    #Testing\n",
    "    saver.restore(sess, \"model_5_6.ckpt-3\")\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "    \n",
    "    \n",
    "# for i in range(0,20):\n",
    "#     startn = 1200+i*10\n",
    "#     endn = startn+9\n",
    "#     print(startn, endn)\n",
    "#     batch_x, batch_y = get_next_batch(startn,endn)\n",
    "#     print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n",
    "#     print(ansx.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1209)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1210, 1219)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1220, 1229)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1230, 1239)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1240, 1249)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1250, 1259)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1260, 1269)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1270, 1279)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1280, 1289)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1290, 1299)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1300, 1309)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1310, 1319)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1320, 1329)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1330, 1339)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1340, 1349)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1350, 1359)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1360, 1369)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1370, 1379)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1380, 1389)\n",
      "('Testing Accuracy:', 1.0)\n",
      "(1390, 1399)\n",
      "('Testing Accuracy:', 1.0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    startn = 1200+i*10\n",
    "    endn = startn+9\n",
    "    print(startn, endn)\n",
    "    batch_x, batch_y = get_next_batch(startn,endn)\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 170)\n"
     ]
    }
   ],
   "source": [
    "#Gradient computation\n",
    "startn = 1200\n",
    "endn = 1209\n",
    "batch_x, batch_y = get_next_batch(startn,endn)\n",
    "outp = tf.slice(pred, [0, 0], [10, 2])\n",
    "var_grad  = tf.gradients(outp, x)[0]\n",
    "#var_grad  = tf.gradients(pred, x)[0]\n",
    "ans = sess.run(var_grad, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "ansx = tf.reshape(ans[0], shape=[-1, 170, 170, 3])\n",
    "#print(sess.run(outp, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n",
    "anspx = sess.run(ansx)\n",
    "anspx1 = anspx[0,:,:,0]\n",
    "anspx2 = anspx[0,:,:,1]\n",
    "anspx3 = anspx[0,:,:,2]\n",
    "print(anspx1.shape)\n",
    "import numpy\n",
    "numpy.savetxt(\"anspx1_26_6\", anspx1, delimiter=\",\")\n",
    "numpy.savetxt(\"anspx2_26_6\", anspx2, delimiter=\",\")\n",
    "numpy.savetxt(\"anspx3_26_6\", anspx3, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 170)\n"
     ]
    }
   ],
   "source": [
    "startn = 1200\n",
    "endn = 1209\n",
    "batch_x, batch_y = get_next_batch(startn,endn)\n",
    "outp = tf.slice(pred, [0, 0], [10, 2])\n",
    "#var_grad  = tf.gradients(outp, x)[0]\n",
    "var_grad  = tf.gradients(pred, x)[0]\n",
    "ans = sess.run(var_grad, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "ansx = tf.reshape(ans[0], shape=[-1, 170, 170, 3])\n",
    "#print(sess.run(outp, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n",
    "\n",
    "\n",
    "#print(ansx.eval())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "anspx = sess.run(ansx)\n",
    "anspx1 = anspx[0,:,:,0]\n",
    "anspx2 = anspx[0,:,:,1]\n",
    "anspx3 = anspx[0,:,:,2]\n",
    "print(anspx1.shape)\n",
    "import numpy\n",
    "numpy.savetxt(\"anspx1_17_14\", anspx1, delimiter=\",\")\n",
    "numpy.savetxt(\"anspx2_17_14\", anspx2, delimiter=\",\")\n",
    "numpy.savetxt(\"anspx3_17_14\", anspx3, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-30d74f724129>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "outp = tf.slice(pred, [0, 0], [10, 2])\n",
    "print(sess.run(outp, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Tensor name \"beta1_power_1\" not found in checkpoint files model_15_5.ckpt-2\n\t [[Node: save_4/restore_slice_1121 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_4/Const_0, save_4/restore_slice_1121/tensor_name, save_4/restore_slice_1121/shape_and_slice)]]\nCaused by op u'save_4/restore_slice_1121', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-b2a18660c919>\", line 541, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 502, in build\n    filename_tensor, vars_to_save, restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 256, in _AddRestoreOps\n    values = self.restore_op(filename_tensor, vs, preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 171, in restore_op\n    preferred_shard=preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py\", line 196, in _restore_slice\n    preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 271, in _restore_slice\n    preferred_shard=preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c9daa8450c16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_15_5.ckpt-2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pranjal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1088\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restore called with invalid save path %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1090\u001b[1;33m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 340\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 564\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 637\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m       raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[1;32m--> 659\u001b[1;33m                                             e.code)\n\u001b[0m\u001b[0;32m    660\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Tensor name \"beta1_power_1\" not found in checkpoint files model_15_5.ckpt-2\n\t [[Node: save_4/restore_slice_1121 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_4/Const_0, save_4/restore_slice_1121/tensor_name, save_4/restore_slice_1121/shape_and_slice)]]\nCaused by op u'save_4/restore_slice_1121', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-b2a18660c919>\", line 541, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 502, in build\n    filename_tensor, vars_to_save, restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 256, in _AddRestoreOps\n    values = self.restore_op(filename_tensor, vs, preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 171, in restore_op\n    preferred_shard=preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py\", line 196, in _restore_slice\n    preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 271, in _restore_slice\n    preferred_shard=preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, \"model_15_5.ckpt-2\")\n",
    "print('pranjal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using eval(): No default session is registered. Use `with sess.as_default()` or pass an explicit session to eval(session=sess)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-62693f3167d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mansx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m170\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m170\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mansx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \"\"\"\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3318\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3320\u001b[1;33m       raise ValueError(\"Cannot evaluate tensor using eval(): No default \"\n\u001b[0m\u001b[0;32m   3321\u001b[0m                        \u001b[1;34m\"session is registered. Use `with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3322\u001b[0m                        \u001b[1;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot evaluate tensor using eval(): No default session is registered. Use `with sess.as_default()` or pass an explicit session to eval(session=sess)"
     ]
    }
   ],
   "source": [
    "startn = 1200\n",
    "endn = 1209\n",
    "batch_x, batch_y = get_next_batch(startn,endn)\n",
    "#batch_x = tf.reshape(batch_x, shape=[-1, 170, 170, 3])\n",
    "var_grad  = tf.gradients(pred, x)[0]\n",
    "#var_gradp = tf.reshape(var_grad, shape=[-1, 170, 170, 3])[0]\n",
    "ans = sess.run(var_grad, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "ansx = tf.reshape(ans[0], shape=[-1, 170, 170, 3])\n",
    "print(ansx.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ansx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-11972990526e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manspx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mansx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ansx' is not defined"
     ]
    }
   ],
   "source": [
    "anspx = sess.run(ansx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 170)\n"
     ]
    }
   ],
   "source": [
    "anspx1 = anspx[0,:,:,0]\n",
    "anspx2 = anspx[0,:,:,1]\n",
    "anspx3 = anspx[0,:,:,2]\n",
    "print(anspx1.shape)\n",
    "import numpy\n",
    "numpy.savetxt(\"anspx1\", anspx1, delimiter=\",\")\n",
    "numpy.savetxt(\"anspx2\", anspx2, delimiter=\",\")\n",
    "numpy.savetxt(\"anspx3\", anspx3, delimiter=\",\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-538aa3e921e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manspx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "img = mpimg.fromarray(anspx[0, :, :, :], 'RGB')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1209)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (10, 86700) for Tensor u'Reshape_8:0', which has shape '(1, 170, 170, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-a12a187868dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mendn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 340\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    554\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (10, 86700) for Tensor u'Reshape_8:0', which has shape '(1, 170, 170, 3)'"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    startn = 1200+i*10\n",
    "    endn = startn+9\n",
    "    print(startn, endn)\n",
    "    batch_x, batch_y = get_next_batch(startn,endn)\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_8:0\", shape=(1, 170, 170, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y = get_next_batch(2501, 2511)\n",
    "print(len(batch_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1209)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_next_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9d1f71405da8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mendn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstartn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mendn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_next_batch' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    startn = 1200+i*10\n",
    "    endn = startn+9\n",
    "    print(startn, endn)\n",
    "    batch_x, batch_y = get_next_batch(startn,endn)\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "inputa = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(inputa[0, 1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
